{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c161593-cc89-4147-979a-abed242dc42c",
   "metadata": {
    "id": "7c161593-cc89-4147-979a-abed242dc42c"
   },
   "source": [
    "# Gemini & ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8GMwFa9nNVSW",
   "metadata": {
    "id": "8GMwFa9nNVSW"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "\"\"\"\n",
    "***************************************\n",
    "00_Initialize_LLM_Jerry.ipynb\n",
    "2025/03/15 001 version\n",
    "***************************************\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4VOpL4jMKbz9",
   "metadata": {
    "id": "4VOpL4jMKbz9"
   },
   "outputs": [],
   "source": [
    "# %env GOOGLE_LOGIN=TRUE\n",
    "# %env REINSTALL=TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7s3rG7k2lmb5",
   "metadata": {
    "collapsed": true,
    "id": "7s3rG7k2lmb5"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"REINSTALL: $REINSTALL\"\n",
    "if [ \"$REINSTALL\" == \"TRUE\" ]\n",
    "then\n",
    "  # requirements.txt가 존한다면\n",
    "  if [ -f requirements.txt ]\n",
    "  then\n",
    "    pip install -r requirements.txt\n",
    "  else\n",
    "    pip install -r langchain_study/requirements.txt\n",
    "  fi\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "k-RbT0W4Hxfb",
   "metadata": {
    "id": "k-RbT0W4Hxfb"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(f\"GOOGLE_LOGIN: {os.environ.get('GOOGLE_LOGIN')}\")\n",
    "if \"GOOGLE_LOGIN\" in os.environ and os.environ[\"GOOGLE_LOGIN\"] == \"TRUE\":\n",
    "  from google.colab import auth\n",
    "  auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AnIx1lkTIq1y",
   "metadata": {
    "id": "AnIx1lkTIq1y"
   },
   "outputs": [],
   "source": [
    "!pip list | grep langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "MNPvvrDc2UqX",
   "metadata": {
    "id": "MNPvvrDc2UqX"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_openai import OpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "import json\n",
    "\n",
    "# public colab인지 일반 jupyter server인지 확인\n",
    "colab = True\n",
    "credentials = {}\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    api_key = userdata.get('openai-key')\n",
    "except:\n",
    "    colab = False\n",
    "\n",
    "print(\"Colab:\", colab)\n",
    "\n",
    "if colab == False:\n",
    "    print(\"Colab에 Secret이 없으므로, credentials.json 파일을 검색합니다.\")\n",
    "    print(\"사용할 항목에만 Secret을 입력해주세요.\")\n",
    "    print(f\"credentials.json 예제: https://github.com/javalove93/langchain_study/raw/refs/heads/main/credentials-sample.json\")\n",
    "    PWD = !pwd\n",
    "    print(f\"  현재 디랙토리: {PWD[0]}\")\n",
    "    print(\"  lang-chain/credentials.json\")\n",
    "    if os.path.exists(\"lang-chain/credentials.json\"):\n",
    "        with open(\"lang-chain/credentials.json\") as f:\n",
    "            credentials = json.load(f)\n",
    "    else:\n",
    "        print(\"  failed\")\n",
    "        print(\"  현재 디랙토리: ./credentials.json\")\n",
    "        if os.path.exists(\"credentials.json\"):\n",
    "            with open(\"credentials.json\") as f:\n",
    "                credentials = json.load(f)\n",
    "                print(\"  success\")\n",
    "        else:\n",
    "            print(\"  failed\")\n",
    "            print(\"  ../credentials.json\")\n",
    "            if os.path.exists(os.path.expanduser(\"../credentials.json\")):\n",
    "                with open(os.path.expanduser(\"../credentials.json\")) as f:\n",
    "                    credentials = json.load(f)\n",
    "                    print(\"  success\")\n",
    "            else:\n",
    "                print(\"  failed\")\n",
    "                print(\"  ../../credentials.json\")\n",
    "                if os.path.exists(os.path.expanduser(\"../../credentials.json\")):\n",
    "                    with open(os.path.expanduser(\"../../credentials.json\")) as f:\n",
    "                        credentials = json.load(f)\n",
    "                        print(\"  success\")\n",
    "                else:\n",
    "                    print(\"  failed\")\n",
    "                    print(\"  ../../../credentials.json\")\n",
    "                    if os.path.exists(os.path.expanduser(\"../../../credentials.json\")):\n",
    "                        with open(os.path.expanduser(\"../../../credentials.json\")) as f:\n",
    "                            credentials = json.load(f)\n",
    "                            print(\"  success\")\n",
    "                    else:\n",
    "                        print(\"credentials.json 파일을 찾을 수 없습니다.\")\n",
    "\n",
    "# Open AI (불필요 하면 제거)\n",
    "if colab:\n",
    "    api_key = userdata.get('openai-key')\n",
    "else:\n",
    "    api_key = credentials.get('openai-key')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = api_key\n",
    "OPENAI_API_KEY = api_key\n",
    "print(f\"OPENAI_API_KEY: {OPENAI_API_KEY[:5]}\")\n",
    "\n",
    "# openai_llm = ChatOpenAI(openai_api_key=API_KEY)\n",
    "openai_llm = ChatOpenAI()\n",
    "# print(openai_llm.invoke(\"Yes means Yes, then No means [ ]?\"))\n",
    "\n",
    "# Anthropic (불필요 하면 제거)\n",
    "if colab:\n",
    "    ANTHROPIC_API_KEY = userdata.get('anthropic-key')\n",
    "else:\n",
    "    ANTHROPIC_API_KEY = credentials.get('anthropic-key')\n",
    "\n",
    "os.environ[\"ANTHROPIC_API_KEY\"] = ANTHROPIC_API_KEY\n",
    "print(f\"ANTHROPIC_API_KEY: {ANTHROPIC_API_KEY[:5]}\")\n",
    "\n",
    "anthropic_llm = ChatAnthropic(model=\"claude-3-opus-20240229\")\n",
    "# print(anthropic_llm.invoke(\"Yes means Yes, then No means [ ]?\"))\n",
    "\n",
    "# Google Gemini (불필요 하면 제거)\n",
    "if colab:\n",
    "    GOOGLE_API_KEY = userdata.get('gemini-api-key')\n",
    "else:\n",
    "    GOOGLE_API_KEY = credentials.get('gemini-api-key')\n",
    "\n",
    "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n",
    "print(f\"GOOGLE_API_KEY: {GOOGLE_API_KEY[:5]}\")\n",
    "\n",
    "gemini_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
    "# setup the gemini pro\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/learn/model-versioning?hl=ko#stable-versions-available.md\n",
    "# text-embedding-004\t2024년 5월 14일\t해당 없음\n",
    "# text-multilingual-embedding-002\t2024년 5월 14일\t해당 없음\n",
    "# https://cloud.google.com/vertex-ai/generative-ai/docs/model-reference/multimodal-embeddings-api?hl=ko\n",
    "# 멀티모달 임베딩\tmultimodalembedding@001\n",
    "gemini_embeddings = GoogleGenerativeAIEmbeddings(model=\"text-multilingual-embedding-002\")\n",
    "# print(gemini_llm.invoke(\"Yes means Yes, then No means [ ]?\"))\n",
    "\n",
    "llm = gemini_llm\n",
    "\n",
    "from vertexai.language_models import TextEmbeddingModel\n",
    "class GoogleTextCustomEmbedding:\n",
    "    def __init__(self, model_name=\"text-multilingual-embedding-002\"):\n",
    "        self.text_model = TextEmbeddingModel.from_pretrained(model_name)\n",
    "\n",
    "    def embed_documents(self, documents):\n",
    "        embeds = self.text_model.get_embeddings(documents)\n",
    "        return [e.values for e in embeds]\n",
    "    \n",
    "    def embed_query(self, query):\n",
    "        return self.text_model.get_embeddings([query])[0].values\n",
    "\n",
    "# Google Search Wrapper (불필요 하면 제거)\n",
    "if colab:\n",
    "    SERPER_API_KEY = userdata.get('google-serper-key')\n",
    "else:\n",
    "    SERPER_API_KEY = credentials.get('google-serper-key')\n",
    "\n",
    "os.environ[\"SERPER_API_KEY\"] = SERPER_API_KEY\n",
    "print(f\"SERPER_API_KEY: {SERPER_API_KEY[:5]}\")\n",
    "\n",
    "# def print_message(aiMessage, messageOnly=True):\n",
    "#     print(\"RESPONSE: {}\".format(aiMessage.content))\n",
    "#     if messageOnly == False:\n",
    "#         print(json.dumps(aiMessage.additional_kwargs, indent=2))\n",
    "#         print(json.dumps(aiMessage.response_metadata, indent=2))\n",
    "#         print(json.dumps(aiMessage.usage_metadata, indent=2))\n",
    "\n",
    "# Lang Smith Tracing (API Key 발급받아야 하며, 불필요하면 제거)\n",
    "%env LANGCHAIN_TRACING_V2=true\n",
    "%env LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "if colab:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('langsmith')\n",
    "else:\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = credentials.get('langsmith')\n",
    "%env LANGCHAIN_PROJECT=langgraph-test\n",
    "print(f\"LANGCHAIN_API_KEY: {os.environ['LANGCHAIN_API_KEY'][:5]}\")\n",
    "\n",
    "# Google Programmable Search API\n",
    "if colab:\n",
    "    GOOGLE_SEARCH_API_KEY = userdata.get('google-search-api-key')\n",
    "    GOOGLE_SEARCH_CSE_ID = userdata.get('google-search-cse')\n",
    "else:\n",
    "    GOOGLE_SEARCH_API_KEY = credentials.get('google-search-api-key')\n",
    "    GOOGLE_SEARCH_CSE_ID = credentials.get('google-search-cse')\n",
    "# API Key가 GenAI API Key와 출돌(권한이 다를 수 있어서 환경 변수에 저장 안함\n",
    "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_SEARCH_API_KEY\n",
    "# os.environ[\"GOOGLE_CSE_ID\"] = GOOGLE_SEARCH_CSE_ID\n",
    "print(f\"GOOGLE_SEARCH_API_KEY: {GOOGLE_SEARCH_API_KEY[:5]}\")\n",
    "print(f\"GOOGLE_SEARCH_CSE_ID: {GOOGLE_SEARCH_CSE_ID[:5]}\")\n",
    "\n",
    "# PINECONE API\n",
    "if colab:\n",
    "    PINECONE_API_KEY = userdata.get('pinecone.io')\n",
    "else:\n",
    "    PINECONE_API_KEY = credentials.get('pinecone.io')\n",
    "os.environ[\"PINECONE_API_KEY\"] = PINECONE_API_KEY\n",
    "print(f\"PINECONE_API_KEY: {PINECONE_API_KEY[:5]}\")\n",
    "\n",
    "# Kaggle 계정 초기화\n",
    "if colab:\n",
    "    KAGGLE_USERNAME = userdata.get('KAGGLE_USERNAME')\n",
    "    KAGGLE_KEY = userdata.get('KAGGLE_KEY')\n",
    "else:\n",
    "    KAGGLE_USERNAME = credentials.get('KAGGLE_USERNAME')\n",
    "    KAGGLE_KEY = credentials.get('KAGGLE_KEY')\n",
    "os.environ[\"KAGGLE_USERNAME\"] = KAGGLE_USERNAME\n",
    "os.environ[\"KAGGLE_KEY\"] = KAGGLE_KEY\n",
    "print(f\"KAGGLE_KEY: {KAGGLE_KEY[:5]}\")\n",
    "\n",
    "# https://smith.langchain.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94082fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "print(f\"SA_KEY_ENABLE: {os.environ.get('SA_KEY_ENABLE')}\")\n",
    "if \"SA_KEY_ENABLE\" in os.environ and os.environ[\"SA_KEY_ENABLE\"] == \"TRUE\":\n",
    "    # Service Account Key\n",
    "    if colab:\n",
    "        SA_KEY = userdata.get('google-sa-json')\n",
    "    else:\n",
    "        SA_KEY = credentials.get('google-sa-json')\n",
    "\n",
    "    with open(\"/tmp/sa_key.json\", \"w\") as f:\n",
    "        sa_key = json.loads(SA_KEY)\n",
    "        f.write(json.dumps(SA_KEY))\n",
    "    os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/tmp/sa_key.json\"\n",
    "    print(f\"GOOGLE_APPLICATION_CREDENTIALS: /tmp/sa_key.json\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
